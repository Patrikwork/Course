{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Patrikwork/Course/blob/main/time_series_forecasting_with_machine_learning_yt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bf63c66",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "papermill": {
          "duration": 0.008028,
          "end_time": "2022-07-05T14:49:40.021433",
          "exception": false,
          "start_time": "2022-07-05T14:49:40.013405",
          "status": "completed"
        },
        "tags": [],
        "id": "8bf63c66"
      },
      "source": [
        "# Time Series Forecasting using XGBoost\n",
        "## Using Machine Learning to Forecast Energy Consumption\n",
        "\n",
        "\n",
        "<img src=\"https://moodle.lut.fi/pluginfile.php/1/theme_maker_lab/logo/1697517856/LAB_eng_NEG.png\" alt=\"drawing\" width=\"350\"/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this cell, we are setting up our environment by importing essential Python libraries that we will use throughout this notebook.\n",
        "\n",
        "pandas: For data manipulation and analysis.\n",
        "numpy: For numerical computing with support for large, multi-dimensional arrays and matrices.\n",
        "matplotlib.pyplot: For creating static, interactive, and animated visualizations in Python.\n",
        "seaborn: For making statistical graphics in Python. It is built on top of matplotlib and closely integrated with pandas data structures.\n",
        "xgboost: An optimized distributed gradient boosting library designed to be highly efficient, flexible, and portable.\n",
        "mean_squared_error from sklearn.metrics: To evaluate the accuracy of our model by calculating the mean squared error.\n",
        "We also set a color palette for consistent plotting styles and apply the 'fivethirtyeight' style for all our plots for aesthetic purposes."
      ],
      "metadata": {
        "id": "QpCxrQ0uyhtP"
      },
      "id": "QpCxrQ0uyhtP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0fc904d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-05T14:49:40.037969Z",
          "iopub.status.busy": "2022-07-05T14:49:40.037212Z",
          "iopub.status.idle": "2022-07-05T14:49:41.456793Z",
          "shell.execute_reply": "2022-07-05T14:49:41.455672Z"
        },
        "papermill": {
          "duration": 1.431176,
          "end_time": "2022-07-05T14:49:41.459708",
          "exception": false,
          "start_time": "2022-07-05T14:49:40.028532",
          "status": "completed"
        },
        "tags": [],
        "id": "b0fc904d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "color_pal = sns.color_palette()\n",
        "plt.style.use('fivethirtyeight')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://raw.githubusercontent.com/Patrikwork/Course/main/PJME_hourly.csv\n",
        "!head -n 5 /content/PJME_hourly.csv"
      ],
      "metadata": {
        "id": "hprWpRbRQ1oI"
      },
      "id": "hprWpRbRQ1oI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "85cc1aab",
      "metadata": {
        "papermill": {
          "duration": 0.006594,
          "end_time": "2022-07-05T14:49:41.473507",
          "exception": false,
          "start_time": "2022-07-05T14:49:41.466913",
          "status": "completed"
        },
        "tags": [],
        "id": "85cc1aab"
      },
      "source": [
        "## Types of Time Series Data\n",
        "\n",
        "![](https://miro.medium.com/max/1400/1*V_RKPeIxCB9CS_2SsLyKXw.jpeg)\n",
        "\n",
        "reference: https://engineering.99x.io/time-series-forecasting-in-machine-learning-3972f7a7a467"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this cell, we are performing the following actions:\n",
        "\n",
        "We load the dataset into a pandas DataFrame. This dataset contains the energy consumption data we want to analyze and forecast.\n",
        "We set the 'Datetime' column as the index of our DataFrame, which is essential for time series analysis since it allows us to manipulate the data based on time conveniently.\n",
        "We ensure that the index is of type datetime by using the pd.to_datetime method. This step is crucial as it enables us to use time-based indexing and resampling techniques that are powerful tools for time series analysis."
      ],
      "metadata": {
        "id": "pTLh4zzSysA5"
      },
      "id": "pTLh4zzSysA5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d87a774",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-05T14:49:41.489232Z",
          "iopub.status.busy": "2022-07-05T14:49:41.488848Z",
          "iopub.status.idle": "2022-07-05T14:49:41.727794Z",
          "shell.execute_reply": "2022-07-05T14:49:41.726477Z"
        },
        "papermill": {
          "duration": 0.249992,
          "end_time": "2022-07-05T14:49:41.730501",
          "exception": false,
          "start_time": "2022-07-05T14:49:41.480509",
          "status": "completed"
        },
        "tags": [],
        "id": "8d87a774"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/PJME_hourly.csv')\n",
        "df = df.set_index('Datetime')\n",
        "df.index = pd.to_datetime(df.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "067b7567",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-05T14:49:41.746405Z",
          "iopub.status.busy": "2022-07-05T14:49:41.745996Z",
          "iopub.status.idle": "2022-07-05T14:49:43.128301Z",
          "shell.execute_reply": "2022-07-05T14:49:43.127072Z"
        },
        "papermill": {
          "duration": 1.395894,
          "end_time": "2022-07-05T14:49:43.133488",
          "exception": false,
          "start_time": "2022-07-05T14:49:41.737594",
          "status": "completed"
        },
        "tags": [],
        "id": "067b7567"
      },
      "outputs": [],
      "source": [
        "df.plot(style='.',\n",
        "        figsize=(15, 5),\n",
        "        color=color_pal[0],\n",
        "        title='PJME Energy Use in MW')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4619779f",
      "metadata": {
        "papermill": {
          "duration": 0.008015,
          "end_time": "2022-07-05T14:49:43.150149",
          "exception": false,
          "start_time": "2022-07-05T14:49:43.142134",
          "status": "completed"
        },
        "tags": [],
        "id": "4619779f"
      },
      "source": [
        "# Train / Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this cell, we are doing the following:\n",
        "\n",
        "We split the dataset into two parts: one for training our model and another for testing its predictions. We are using '01-01-2015' as the cut-off date, with data before this date used for training and data on or after this date used for testing.\n",
        "We then plot the training and test sets to visualize the split. The training set is the portion of the data that the model learns from, and the test set is the part that we use to evaluate the model's forecasting abilities.\n",
        "We also draw a black dashed line at the '01-01-2015' cut-off date to clearly indicate the division between the training and test data on the plot."
      ],
      "metadata": {
        "id": "ori3abpYy6V9"
      },
      "id": "ori3abpYy6V9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11f8482f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-05T14:49:43.168881Z",
          "iopub.status.busy": "2022-07-05T14:49:43.168449Z",
          "iopub.status.idle": "2022-07-05T14:49:45.109479Z",
          "shell.execute_reply": "2022-07-05T14:49:45.108662Z"
        },
        "papermill": {
          "duration": 1.95336,
          "end_time": "2022-07-05T14:49:45.111787",
          "exception": false,
          "start_time": "2022-07-05T14:49:43.158427",
          "status": "completed"
        },
        "tags": [],
        "id": "11f8482f"
      },
      "outputs": [],
      "source": [
        "train = df.loc[df.index < '01-01-2015']\n",
        "test = df.loc[df.index >= '01-01-2015']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "train.plot(ax=ax, label='Training Set', title='Data Train/Test Split')\n",
        "test.plot(ax=ax, label='Test Set')\n",
        "ax.axvline('01-01-2015', color='black', ls='--')\n",
        "ax.legend(['Training Set', 'Test Set'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this cell, we're focusing on a smaller slice of our data:\n",
        "\n",
        "We filter the DataFrame to show only a single week of data, from '01-01-2010' to '01-08-2010'.\n",
        "This filtered data is then plotted to give us a closer look at what a typical week looks like in our time series. This can help us understand the daily and weekly patterns and variations in the energy consumption data we're analyzing."
      ],
      "metadata": {
        "id": "VXfdyfdUzCeD"
      },
      "id": "VXfdyfdUzCeD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84135b1a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-05T14:49:45.131880Z",
          "iopub.status.busy": "2022-07-05T14:49:45.131232Z",
          "iopub.status.idle": "2022-07-05T14:49:45.384728Z",
          "shell.execute_reply": "2022-07-05T14:49:45.383394Z"
        },
        "papermill": {
          "duration": 0.266345,
          "end_time": "2022-07-05T14:49:45.387468",
          "exception": false,
          "start_time": "2022-07-05T14:49:45.121123",
          "status": "completed"
        },
        "tags": [],
        "id": "84135b1a"
      },
      "outputs": [],
      "source": [
        "df.loc[(df.index > '01-01-2010') & (df.index < '01-08-2010')] \\\n",
        "    .plot(figsize=(15, 5), title='Week Of Data')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e4a15e5",
      "metadata": {
        "papermill": {
          "duration": 0.009814,
          "end_time": "2022-07-05T14:49:45.407566",
          "exception": false,
          "start_time": "2022-07-05T14:49:45.397752",
          "status": "completed"
        },
        "tags": [],
        "id": "4e4a15e5"
      },
      "source": [
        "# Feature Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this cell, we define a function create_features which creates new columns in our DataFrame that represent various time components of the index. These are derived from the timestamp of each observation and include:\n",
        "\n",
        "hour: The hour of the day.\n",
        "dayofweek: The day of the week.\n",
        "quarter: The quarter of the year.\n",
        "month: The month of the year.\n",
        "year: The year.\n",
        "dayofyear: The day of the year.\n",
        "dayofmonth: The day of the month.\n",
        "weekofyear: The week of the year.\n",
        "We then apply this function to our DataFrame, enriching it with these features which will be useful for our time series forecasting model to identify and learn patterns based on time.\n",
        "\n"
      ],
      "metadata": {
        "id": "V3GV2Y4ozPSu"
      },
      "id": "V3GV2Y4ozPSu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ef8ba95",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-05T14:49:45.430239Z",
          "iopub.status.busy": "2022-07-05T14:49:45.429872Z",
          "iopub.status.idle": "2022-07-05T14:49:45.602061Z",
          "shell.execute_reply": "2022-07-05T14:49:45.600976Z"
        },
        "papermill": {
          "duration": 0.186611,
          "end_time": "2022-07-05T14:49:45.604832",
          "exception": false,
          "start_time": "2022-07-05T14:49:45.418221",
          "status": "completed"
        },
        "tags": [],
        "id": "3ef8ba95"
      },
      "outputs": [],
      "source": [
        "def create_features(df):\n",
        "    \"\"\"\n",
        "    Create time series features based on time series index.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    df['hour'] = df.index.hour\n",
        "    df['dayofweek'] = df.index.dayofweek\n",
        "    df['quarter'] = df.index.quarter\n",
        "    df['month'] = df.index.month\n",
        "    df['year'] = df.index.year\n",
        "    df['dayofyear'] = df.index.dayofyear\n",
        "    df['dayofmonth'] = df.index.day\n",
        "    df['weekofyear'] = df.index.isocalendar().week\n",
        "    return df\n",
        "\n",
        "df = create_features(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca580ee4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-02T18:55:43.448999Z",
          "iopub.status.busy": "2022-07-02T18:55:43.448667Z",
          "iopub.status.idle": "2022-07-02T18:55:43.536534Z",
          "shell.execute_reply": "2022-07-02T18:55:43.535473Z",
          "shell.execute_reply.started": "2022-07-02T18:55:43.448971Z"
        },
        "papermill": {
          "duration": 0.010383,
          "end_time": "2022-07-05T14:49:45.625175",
          "exception": false,
          "start_time": "2022-07-05T14:49:45.614792",
          "status": "completed"
        },
        "tags": [],
        "id": "ca580ee4"
      },
      "source": [
        "# Visualize our Feature / Target Relationship"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell produces a boxplot to visualize the distribution of energy consumption (PJME_MW) for each month. The following actions are performed:\n",
        "\n",
        "We use seaborn's boxplot to create the plot, which shows the median, quartiles, and outliers for energy consumption in each month.\n",
        "This visualization helps to identify seasonal trends and the variability in energy consumption throughout the year."
      ],
      "metadata": {
        "id": "yz99nVwmzTjS"
      },
      "id": "yz99nVwmzTjS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4f3a98e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-05T14:49:45.647598Z",
          "iopub.status.busy": "2022-07-05T14:49:45.646866Z",
          "iopub.status.idle": "2022-07-05T14:49:46.209854Z",
          "shell.execute_reply": "2022-07-05T14:49:46.208681Z"
        },
        "papermill": {
          "duration": 0.577083,
          "end_time": "2022-07-05T14:49:46.212508",
          "exception": false,
          "start_time": "2022-07-05T14:49:45.635425",
          "status": "completed"
        },
        "tags": [],
        "id": "f4f3a98e"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.boxplot(data=df, x='hour', y='PJME_MW')\n",
        "ax.set_title('MW by Hour')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0d50516",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-05T14:49:46.236209Z",
          "iopub.status.busy": "2022-07-05T14:49:46.235464Z",
          "iopub.status.idle": "2022-07-05T14:49:46.611825Z",
          "shell.execute_reply": "2022-07-05T14:49:46.610567Z"
        },
        "papermill": {
          "duration": 0.391176,
          "end_time": "2022-07-05T14:49:46.614381",
          "exception": false,
          "start_time": "2022-07-05T14:49:46.223205",
          "status": "completed"
        },
        "tags": [],
        "id": "c0d50516"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.boxplot(data=df, x='month', y='PJME_MW', palette='Blues')\n",
        "ax.set_title('MW by Month')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cbb4e32",
      "metadata": {
        "papermill": {
          "duration": 0.010945,
          "end_time": "2022-07-05T14:49:46.636956",
          "exception": false,
          "start_time": "2022-07-05T14:49:46.626011",
          "status": "completed"
        },
        "tags": [],
        "id": "1cbb4e32"
      },
      "source": [
        "# Create our Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this cell, we are preparing our dataset for the machine learning model:\n",
        "\n",
        "We apply the create_features function to both the training and test sets to generate the time series features.\n",
        "We define the features (FEATURES) that we will use to train our model and the target variable (TARGET) that we want to predict.\n",
        "We then create X_train and y_train from the training set, which contain the features and target variable respectively.\n",
        "Similarly, we create X_test and y_test from the test set. These will be used to evaluate the performance of our model after training."
      ],
      "metadata": {
        "id": "5MsGhSgRzgDr"
      },
      "id": "5MsGhSgRzgDr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "652b84a8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-05T14:49:46.661356Z",
          "iopub.status.busy": "2022-07-05T14:49:46.660632Z",
          "iopub.status.idle": "2022-07-05T14:49:46.846798Z",
          "shell.execute_reply": "2022-07-05T14:49:46.845870Z"
        },
        "papermill": {
          "duration": 0.20116,
          "end_time": "2022-07-05T14:49:46.849298",
          "exception": false,
          "start_time": "2022-07-05T14:49:46.648138",
          "status": "completed"
        },
        "tags": [],
        "id": "652b84a8"
      },
      "outputs": [],
      "source": [
        "train = create_features(train)\n",
        "test = create_features(test)\n",
        "\n",
        "FEATURES = ['dayofyear', 'hour', 'dayofweek', 'quarter', 'month', 'year']\n",
        "TARGET = 'PJME_MW'\n",
        "\n",
        "X_train = train[FEATURES]\n",
        "y_train = train[TARGET]\n",
        "\n",
        "X_test = test[FEATURES]\n",
        "y_test = test[TARGET]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this cell, we are initializing and training our machine learning model:\n",
        "\n",
        "We use the XGBRegressor from the xgboost library, which is a popular and powerful model for regression tasks that uses gradient boosting on decision trees.\n",
        "We set various parameters for the model, such as n_estimators (the number of trees), max_depth, and learning_rate.\n",
        "We also use early_stopping_rounds to prevent overfitting by stopping the training if the test set error doesn't improve for a given number of rounds.\n",
        "The reg.fit method trains the model on our training data (X_train, y_train) and also evaluates it on both the training set and test set (X_test, y_test), providing verbose output every 100 rounds.\n"
      ],
      "metadata": {
        "id": "r1Uo67hazqSt"
      },
      "id": "r1Uo67hazqSt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "611df9ad",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-05T14:49:46.874744Z",
          "iopub.status.busy": "2022-07-05T14:49:46.874324Z",
          "iopub.status.idle": "2022-07-05T14:50:13.610262Z",
          "shell.execute_reply": "2022-07-05T14:50:13.609087Z"
        },
        "papermill": {
          "duration": 26.75173,
          "end_time": "2022-07-05T14:50:13.612588",
          "exception": false,
          "start_time": "2022-07-05T14:49:46.860858",
          "status": "completed"
        },
        "tags": [],
        "id": "611df9ad"
      },
      "outputs": [],
      "source": [
        "reg = xgb.XGBRegressor(base_score=0.5, booster='gbtree',\n",
        "                       n_estimators=1000,\n",
        "                       early_stopping_rounds=50,\n",
        "                       objective='reg:linear',\n",
        "                       max_depth=3,\n",
        "                       learning_rate=0.01)\n",
        "reg.fit(X_train, y_train,\n",
        "        eval_set=[(X_train, y_train), (X_test, y_test)],\n",
        "        verbose=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57babaad",
      "metadata": {
        "papermill": {
          "duration": 0.012097,
          "end_time": "2022-07-05T14:50:13.636564",
          "exception": false,
          "start_time": "2022-07-05T14:50:13.624467",
          "status": "completed"
        },
        "tags": [],
        "id": "57babaad"
      },
      "source": [
        "# Feature Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training the model, this cell generates a plot to visualize the importance of each feature:\n",
        "\n",
        "We create a DataFrame fi from the model's feature_importances_, which indicates how much each feature contributes to the model's predictions.\n",
        "We then sort and plot these importances using a horizontal bar chart.\n",
        "This visualization is crucial for understanding which features are most influential in the model's forecasts, and it can inform us about the relevance of different time components to the energy consumption pattern."
      ],
      "metadata": {
        "id": "HGJNL0EtzyAb"
      },
      "id": "HGJNL0EtzyAb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "471efcbd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-05T14:50:13.662653Z",
          "iopub.status.busy": "2022-07-05T14:50:13.662244Z",
          "iopub.status.idle": "2022-07-05T14:50:13.874423Z",
          "shell.execute_reply": "2022-07-05T14:50:13.873059Z"
        },
        "papermill": {
          "duration": 0.22845,
          "end_time": "2022-07-05T14:50:13.877111",
          "exception": false,
          "start_time": "2022-07-05T14:50:13.648661",
          "status": "completed"
        },
        "tags": [],
        "id": "471efcbd"
      },
      "outputs": [],
      "source": [
        "fi = pd.DataFrame(data=reg.feature_importances_,\n",
        "             index=reg.feature_names_in_,\n",
        "             columns=['importance'])\n",
        "fi.sort_values('importance').plot(kind='barh', title='Feature Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9743e3c7",
      "metadata": {
        "papermill": {
          "duration": 0.012188,
          "end_time": "2022-07-05T14:50:13.901939",
          "exception": false,
          "start_time": "2022-07-05T14:50:13.889751",
          "status": "completed"
        },
        "tags": [],
        "id": "9743e3c7"
      },
      "source": [
        "# Forecast on Test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we use our trained model to make predictions and visualize them:\n",
        "\n",
        "We add a new column prediction to the test set, which contains the model's predictions for the test period.\n",
        "We merge these predictions back into the original DataFrame df so we can compare them with the actual values.\n",
        "We plot the true energy consumption data and overlay the predictions to visually assess how well our model has learned the pattern.\n",
        "A legend is added to help distinguish between the true data (Truth Data) and the model's predictions (Predictions).\n",
        "The title 'Raw Data and Prediction' indicates that we are looking at the actual and forecasted values together."
      ],
      "metadata": {
        "id": "RvXhAnGDz6pR"
      },
      "id": "RvXhAnGDz6pR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64d15a4a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-05T14:50:13.929567Z",
          "iopub.status.busy": "2022-07-05T14:50:13.928878Z",
          "iopub.status.idle": "2022-07-05T14:50:17.796824Z",
          "shell.execute_reply": "2022-07-05T14:50:17.795686Z"
        },
        "papermill": {
          "duration": 3.885446,
          "end_time": "2022-07-05T14:50:17.799940",
          "exception": false,
          "start_time": "2022-07-05T14:50:13.914494",
          "status": "completed"
        },
        "tags": [],
        "id": "64d15a4a"
      },
      "outputs": [],
      "source": [
        "test['prediction'] = reg.predict(X_test)\n",
        "df = df.merge(test[['prediction']], how='left', left_index=True, right_index=True)\n",
        "ax = df[['PJME_MW']].plot(figsize=(15, 5))\n",
        "df['prediction'].plot(ax=ax, style='.')\n",
        "plt.legend(['Truth Data', 'Predictions'])\n",
        "ax.set_title('Raw Dat and Prediction')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell focuses on a detailed comparison of actual data and predictions for a specific week:\n",
        "\n",
        "We filter the DataFrame df to visualize the actual (PJME_MW) and predicted (prediction) energy consumption values for the first week of April 2018.\n",
        "We plot these values to see how closely the predictions match the actual data on a more granular level.\n",
        "The legend differentiates between the 'Truth Data' (actual values) and 'Prediction' (model forecast), allowing us to visually assess the model's performance for this specific period."
      ],
      "metadata": {
        "id": "8JipZPLk0Cw4"
      },
      "id": "8JipZPLk0Cw4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72a926c3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-05T14:50:17.829150Z",
          "iopub.status.busy": "2022-07-05T14:50:17.828159Z",
          "iopub.status.idle": "2022-07-05T14:50:18.090591Z",
          "shell.execute_reply": "2022-07-05T14:50:18.089392Z"
        },
        "papermill": {
          "duration": 0.279996,
          "end_time": "2022-07-05T14:50:18.093473",
          "exception": false,
          "start_time": "2022-07-05T14:50:17.813477",
          "status": "completed"
        },
        "tags": [],
        "id": "72a926c3"
      },
      "outputs": [],
      "source": [
        "ax = df.loc[(df.index > '04-01-2018') & (df.index < '04-08-2018')]['PJME_MW'] \\\n",
        "    .plot(figsize=(15, 5), title='Week Of Data')\n",
        "df.loc[(df.index > '04-01-2018') & (df.index < '04-08-2018')]['prediction'] \\\n",
        "    .plot(style='.')\n",
        "plt.legend(['Truth Data','Prediction'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09568c1b",
      "metadata": {
        "papermill": {
          "duration": 0.014338,
          "end_time": "2022-07-05T14:50:18.122461",
          "exception": false,
          "start_time": "2022-07-05T14:50:18.108123",
          "status": "completed"
        },
        "tags": [],
        "id": "09568c1b"
      },
      "source": [
        "# Score (RMSE & MAPE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the final cell, we calculate the model's performance metric:\n",
        "\n",
        "We use the mean_squared_error function from sklearn.metrics, taking the square root of the result to get the Root Mean Squared Error (RMSE) score.\n",
        "The RMSE score is a common measure of the accuracy of a regression model, indicating the standard deviation of the residuals (prediction errors).\n",
        "We print out the RMSE score, formatted to two decimal places, which gives us a quantitative measure of how well our model is performing on the test set."
      ],
      "metadata": {
        "id": "-xQG6yh40JMH"
      },
      "id": "-xQG6yh40JMH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ca5128a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-05T14:50:18.154328Z",
          "iopub.status.busy": "2022-07-05T14:50:18.153402Z",
          "iopub.status.idle": "2022-07-05T14:50:18.161870Z",
          "shell.execute_reply": "2022-07-05T14:50:18.160512Z"
        },
        "papermill": {
          "duration": 0.026642,
          "end_time": "2022-07-05T14:50:18.164035",
          "exception": false,
          "start_time": "2022-07-05T14:50:18.137393",
          "status": "completed"
        },
        "tags": [],
        "id": "2ca5128a"
      },
      "outputs": [],
      "source": [
        "score = np.sqrt(mean_squared_error(test['PJME_MW'], test['prediction']))\n",
        "print(f'RMSE Score on Test set: {score:0.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To gain a clearer understanding of our model's prediction accuracy, we will compute the Mean Absolute Percentage Error (MAPE). This metric is more intuitive than RMSE because it expresses errors as a percentage of the actual values. Here's what we're doing:\n",
        "\n",
        "We calculate the MAPE using the actual values from the test set and the predicted values from our model.\n",
        "The MAPE provides the average absolute error in percentage terms, which is straightforward to interpret â€” a MAPE of 5% would mean that the average prediction error is 5% of the actual value.\n",
        "We multiply the MAPE by 100 to convert it to a percentage, making it even easier to read and understand.\n",
        "We aim for the MAPE to be as low as possible, with 0% representing perfect predictions.\n",
        "This metric will help us quantify the performance of our model in terms that are more meaningful for business stakeholders and less technical users."
      ],
      "metadata": {
        "id": "0eZbkHDD1zEs"
      },
      "id": "0eZbkHDD1zEs"
    },
    {
      "cell_type": "code",
      "source": [
        "mape_score = mean_absolute_percentage_error(y_test, test['prediction'])\n",
        "print(f'MAPE Score on Test set: {mape_score * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "Sc6lbfCK1iCG"
      },
      "id": "Sc6lbfCK1iCG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5d3c1169",
      "metadata": {
        "papermill": {
          "duration": 0.014983,
          "end_time": "2022-07-05T14:50:18.194478",
          "exception": false,
          "start_time": "2022-07-05T14:50:18.179495",
          "status": "completed"
        },
        "tags": [],
        "id": "5d3c1169"
      },
      "source": [
        "# Calculate Error\n",
        "- Look at the worst and best predicted days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "929b6fc9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-05T14:50:18.227021Z",
          "iopub.status.busy": "2022-07-05T14:50:18.226596Z",
          "iopub.status.idle": "2022-07-05T14:50:18.269108Z",
          "shell.execute_reply": "2022-07-05T14:50:18.268066Z"
        },
        "papermill": {
          "duration": 0.06133,
          "end_time": "2022-07-05T14:50:18.271408",
          "exception": false,
          "start_time": "2022-07-05T14:50:18.210078",
          "status": "completed"
        },
        "tags": [],
        "id": "929b6fc9"
      },
      "outputs": [],
      "source": [
        "test['error'] = np.abs(test[TARGET] - test['prediction'])\n",
        "test['date'] = test.index.date\n",
        "test.groupby(['date'])['error'].mean().sort_values(ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the Series to DataFrame\n",
        "top_errors_by_date_df = top_errors_by_date.reset_index()\n",
        "\n",
        "# Print the DataFrame\n",
        "print(top_errors_by_date_df)"
      ],
      "metadata": {
        "id": "Q9bdn-MGkeKi"
      },
      "id": "Q9bdn-MGkeKi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving and Using the Trained Model Elsewhere (DON'T RUN THE CODE HERE)\n",
        "\n",
        "After training your machine learning model, you may want to save it so that you can use it in a different environment or application. This involves two main steps: saving the model to a file and then loading it from that file elsewhere. Here's how to do it:\n",
        "\n",
        "Save the Model: Use joblib to save the model to a file. This is efficient for models with large numpy arrays.\n"
      ],
      "metadata": {
        "id": "hJA5J1m336Cl"
      },
      "id": "hJA5J1m336Cl"
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model to a file\n",
        "joblib.dump(reg, 'model_filename.joblib')\n"
      ],
      "metadata": {
        "id": "dfK0KSuz3_yx"
      },
      "id": "dfK0KSuz3_yx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace reg with the variable name of your trained model and 'model_filename.joblib' with the desired file name.\n",
        "\n",
        "Transfer the Model File: Move the saved file to the new environment by your preferred method (e.g., USB, cloud storage, version control).\n",
        "\n",
        "Load the Model: In the new environment, load the model from the file."
      ],
      "metadata": {
        "id": "-waANdDU4ENS"
      },
      "id": "-waANdDU4ENS"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from the file\n",
        "loaded_model = joblib.load('model_filename.joblib')"
      ],
      "metadata": {
        "id": "_pcKXj0Y4P6l"
      },
      "id": "_pcKXj0Y4P6l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the Model: Make predictions using the loaded model."
      ],
      "metadata": {
        "id": "YdHHYDfD4EFu"
      },
      "id": "YdHHYDfD4EFu"
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the loaded model to make predictions\n",
        "predictions = loaded_model.predict(data_to_predict)"
      ],
      "metadata": {
        "id": "_a7Q7f9M4ULA"
      },
      "id": "_a7Q7f9M4ULA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensure that data_to_predict is preprocessed in the same way as the training data was.\n",
        "\n",
        "Remember to replace data_to_predict with your actual data when making predictions.\n",
        "\n"
      ],
      "metadata": {
        "id": "CvZk_u1n4Ycm"
      },
      "id": "CvZk_u1n4Ycm"
    },
    {
      "cell_type": "markdown",
      "id": "362e6234",
      "metadata": {
        "papermill": {
          "duration": 0.015442,
          "end_time": "2022-07-05T14:50:18.302044",
          "exception": false,
          "start_time": "2022-07-05T14:50:18.286602",
          "status": "completed"
        },
        "tags": [],
        "id": "362e6234"
      },
      "source": [
        "# Next Steps\n",
        "- More robust cross validation\n",
        "- Add more features (weather forecast, holidays)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 48.956079,
      "end_time": "2022-07-05T14:50:19.170306",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-07-05T14:49:30.214227",
      "version": "2.3.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}